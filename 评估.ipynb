{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d82247eb-997a-489f-8a61-ef04d52ceb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ISR.models import RRDN\n",
    "from ISR.models import RDN\n",
    "\n",
    "rdn = RRDN(weights='../rrdn-C4-D3-G32-G032-T10-x4/Perceptual/rrdn-C4-D3-G32-G032-T10-x4_epoch299.hdf5')\n",
    "# rdn = RDN(weights='../rdn-C6-D20-G64-G064-x2/PSNR-driven/rdn-C6-D20-G64-G064-x2_PSNR_epoch086.hdf5')\n",
    "\n",
    "img = Image.open('kind_++.jpg')\n",
    "lr_img = np.array(img)\n",
    "\n",
    "sr_img = rdn.predict(lr_img)\n",
    "\n",
    "a=Image.fromarray(sr_img)\n",
    "a.save(\"kind_++-sr.jpg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0a8cab-089f-4dab-985c-92c4659f254f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a7669af-e2ef-4b46-805a-b78961e43210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR score: 18.658642347791126\n",
      "SSIM score: 0.4685657381872901\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\WhiteNight\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "LPIPS score: 0.5011107921600342\n",
      "MSE score: 70.1799034630312\n"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from lpips import LPIPS\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    # img1 and img2 have range [0, 255]\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    mse = np.mean((img1 - img2)**2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    # 计算SSIM\n",
    "    return ssim(img1, img2, data_range=img2.max() - img2.min())\n",
    "\n",
    "\n",
    "img1 = Image.open('source.jpg')\n",
    "img2 = Image.open('kind_++.jpg')\n",
    "img2 = img2.resize(img1.size)\n",
    "img1_gray = img1.convert('L')\n",
    "img2_gray = img2.convert('L')\n",
    "img1_np = np.array(img1)\n",
    "img2_np = np.array(img2)\n",
    "img1_gray_np = np.array(img1_gray)\n",
    "img2_gray_np = np.array(img2_gray)\n",
    "\n",
    "def calculate_lpips(img1, img2):\n",
    "    # 将图像转换为张量，并将其归一化为[-1, 1]范围内的值\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "    img1 = transform(img1).unsqueeze(0)\n",
    "    img2 = transform(img2).unsqueeze(0)\n",
    "    # 初始化LPIPS模型\n",
    "    lpips_model = LPIPS(net='alex')\n",
    "    # 计算LPIPS\n",
    "    return lpips_model(img1, img2)\n",
    "\n",
    "def calculate_mse(img1, img2):\n",
    "    # 计算MSE\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    return mse\n",
    "\n",
    "print(f'PSNR score: {calculate_psnr(img1_np, img2_np)}')\n",
    "# 打印SSIM得分\n",
    "print(\"SSIM score:\", calculate_ssim(img1_gray_np, img2_gray_np))\n",
    "print(\"LPIPS score:\", calculate_lpips(img1, img2).item())\n",
    "print(\"MSE score:\", calculate_mse(img1_np, img2_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92788c53-91cc-43c8-bd8a-cf5d562689d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe9abd9-a49d-46f1-b2e2-1b813361a103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\WhiteNight\\miniconda3\\envs\\d2l\\lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "LPIPS score: 0.006432544440031052\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from lpips import LPIPS\n",
    "\n",
    "# 读取图像\n",
    "img1 = Image.open('3.jpg')\n",
    "img2 = Image.open('3-sr.jpg')\n",
    "img2 = img2.resize((img2.size[0] // 4, img2.size[1] // 4))\n",
    "\n",
    "# 将图像转换为张量，并将其归一化为[-1, 1]范围内的值\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "img1_tensor = transform(img1).unsqueeze(0)\n",
    "img2_tensor = transform(img2).unsqueeze(0)\n",
    "\n",
    "# 初始化LPIPS模型\n",
    "lpips_model = LPIPS(net='alex')\n",
    "\n",
    "# 计算LPIPS\n",
    "lpips_score = lpips_model(img1_tensor, img2_tensor)\n",
    "\n",
    "# 打印LPIPS得分\n",
    "print(\"LPIPS score:\", lpips_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b37bae6-dca2-47f4-9e92-a6dfd7955b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE score: 10.328325467375366\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 读取图像\n",
    "img1 = Image.open('3.jpg')\n",
    "img2 = Image.open('3-sr.jpg')\n",
    "\n",
    "# 将图像转换为NumPy数组\n",
    "img1_np = np.array(img1)\n",
    "img2_np = np.array(img2)\n",
    "img2_np = img2.resize((img2.size[0] // 4, img2.size[1] // 4))\n",
    "\n",
    "# 计算MSE\n",
    "mse = np.mean((img1_np - img2_np) ** 2)\n",
    "\n",
    "# 打印MSE得分\n",
    "print(\"MSE score:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062ab32d-a8f2-45b9-99c2-0877b43af47d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-27T03:57:39.433736Z",
     "iopub.status.busy": "2023-05-27T03:57:39.433736Z",
     "iopub.status.idle": "2023-05-27T03:57:39.458038Z",
     "shell.execute_reply": "2023-05-27T03:57:39.457036Z",
     "shell.execute_reply.started": "2023-05-27T03:57:39.433736Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"kind_++.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "equalized_image = cv2.equalizeHist(gray_image)\n",
    "cv2.imwrite(\"equalized_image.png\", equalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943931ae-00ea-4933-a779-0091ecef4a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
